(ns {{ namespace }}
  (:require [gm.source.{{ source.type }} :as source]
            [gm.pipeline.core :as pipeline]
            [gm.sink.core :as sink]
            [gm.sink.{{ sink.type }} :as {{ sink.type }}]
            {% if watermark_enabled %}[gm.utils.watermark :as watermark]{% endif %}
            [clojure.tools.logging :as log])
  (:gen-class))

;; Configuration
(def config
  {:cassandra {:contact-points [(or (System/getenv "{{ source.type | upcase }}_HOST") "{{ source.default_host }}")]
               :port {{ source.default_port }}
               :username (System/getenv "{{ source.type | upcase }}_USER")
               :password (System/getenv "{{ source.type | upcase }}_PASSWORD")
               {% if source.schema %}:keyspace "{{ source.schema }}"{% endif %}}

   :druid {:base-url (or (System/getenv "{{ sink.type | upcase }}_URL") "{{ sink.default_url }}")
           :auth {:type :basic
                  :username (System/getenv "{{ sink.type | upcase }}_USER")
                  :password (System/getenv "{{ sink.type | upcase }}_PASSWORD")}}

   :pipeline {:batch-size {{ batch_size }}
              :source-table "{{ source.table }}"
              :dest-table "{{ sink.table }}"
              :source-type "{{ source.type }}"
              :timestamp-column :{{ timestamp_column }}
              :id-column :{{ id_column | default: "id" }}
              {% if watermark_enabled %}:watermark-file ".pipeline-watermark.edn"{% endif %}}})

(def transform-record (pipeline/make-transform-record config))

{% if watermark_enabled %}
;; Incremental pipeline execution
(defn run-incremental-pipeline []
  (log/info "Starting incremental {{ source.type }} -> {{ sink.type }} pipeline")
  (let [start-time (System/currentTimeMillis)
        watermark-file (:watermark-file (:pipeline config))
        wm (watermark/load-watermark watermark-file)
        timestamp-col (:timestamp-column (:pipeline config))
        id-col (:id-column (:pipeline config))]

    (log/info "Watermark stats:" (watermark/watermark-stats wm))

    (let [source-conn (-> (source/create-adapter)
                          (source/connect (:{{ source.type }} config)))
          sink-conn (-> ({{ sink.type }}/create-adapter (:{{ sink.type }} config))
                       (sink/connect (:{{ sink.type }} config)))]

      (try
        (let [base-query (-> (source/query-spec (:source-table (:pipeline config)))
                             (source/select-columns [{% for col in columns %}:{{ col }}{% unless forloop.last %} {% endunless %}{% endfor %}]))
              
              ;; Build composite incremental condition
              incremental-condition (watermark/build-incremental-condition wm timestamp-col id-col)
              
              query (if incremental-condition
                      (do
                        (log/info "Fetching records with composite condition")
                        (-> base-query
                            (source/where incremental-condition)
                            (source/allow-filtering)))
                      (do
                        (log/info "No watermark found, fetching all records")
                        base-query))]

          (log/info "Fetching data from {{ source.type }}...")
          (let [source-data (source/fetch source-conn query)
                ;; Additional safety filter (in case DB doesn't support composite query)
                filtered-data (watermark/filter-already-processed source-data wm timestamp-col id-col)
                record-count (count filtered-data)]

            (if (zero? record-count)
              (do
                (log/info "No new records to process")
                {:success true :records-processed 0 :message "No new data"})

              (do
                (log/info "Fetched" record-count "new records")
                (let [transformed-data (map transform-record filtered-data)
                      ;; Get max timestamp and IDs at that timestamp
                      [max-timestamp ids-at-max] (watermark/find-max-timestamp filtered-data timestamp-col id-col)]

                  (log/info "Max timestamp:" max-timestamp "with" (count ids-at-max) "records")

                  (let [result (if (> record-count (:batch-size (:pipeline config)))
                                 (sink/batch-insert sink-conn
                                                   (:dest-table (:pipeline config))
                                                   transformed-data
                                                   (:batch-size (:pipeline config)))
                                 (sink/insert sink-conn
                                             (:dest-table (:pipeline config))
                                             transformed-data))]

                    ;; Save watermark with processed IDs
                    (watermark/save-watermark watermark-file max-timestamp ids-at-max
                                            {:records-processed record-count})

                    (let [elapsed (- (System/currentTimeMillis) start-time)]
                      {:success true
                       :records-processed record-count
                       :elapsed-ms elapsed
                       :previous-watermark (:last-timestamp wm)
                       :new-watermark max-timestamp
                       :processed-ids (count ids-at-max)})))))))

        (finally
          (source/disconnect source-conn)
          (sink/disconnect sink-conn))))))

;; Full reload
(defn run-full-reload []
  (log/info "Starting FULL RELOAD")
  (watermark/delete-watermark (:watermark-file (:pipeline config)))
  (run-incremental-pipeline))
{% endif %}

;; Regular pipeline
(defn run-pipeline []
  (log/info "Starting {{ source.type }} -> {{ sink.type }} pipeline")
  (let [start-time (System/currentTimeMillis)
        source-conn (-> (source/create-adapter)
                        (source/connect (:{{ source.type }} config)))
        sink-conn (-> ({{ sink.type }}/create-adapter (:{{ sink.type }} config))
                     (sink/connect (:{{ sink.type }} config)))]

    (try
      (let [base-query (-> (source/query-spec (:source-table (:pipeline config)))
                          (source/select-columns [{% for col in columns %}:{{ col }}{% unless forloop.last %} {% endunless %}{% endfor %}]))

            ;; Apply static WHERE conditions if any
            {% if conditions.size > 0 %}
            where-conditions (pipeline/build-where-clause [
              {% for cond in conditions %}
              {:type :{{ cond.type }}
               :column :{{ cond.column }}
               {% if cond.type == "in_expression" %}
               :values [{{ cond.values_formatted }}]
               :negated {{ cond.negated }}
               {% else %}
               :operator "{{ cond.operator }}"
               :value {{ cond.value }}
               {% endif %}}{% unless forloop.last %},{% endunless %}
              {% endfor %}])
            
            query (source/where base-query where-conditions)
            {% else %}
            query base-query
            {% endif %}

            
            source-data (source/fetch source-conn query)
            record-count (count source-data)]

        (log/info "Fetched" record-count "records")

        (let [transformed-data (map transform-record source-data)
              result (sink/insert sink-conn
                                 (:dest-table (:pipeline config))
                                 transformed-data)]

          {:success true
           :records-processed record-count
           :elapsed-ms (- (System/currentTimeMillis) start-time)}))

      (finally
        (source/disconnect source-conn)
        (sink/disconnect sink-conn)))))

;; Main entry point
(defn -main [& args]
  (let [mode (first args)]
    (case mode
      {% if watermark_enabled %}"incremental" (run-incremental-pipeline)
      "full-reload" (run-full-reload)
      {% endif %}(run-pipeline))))
