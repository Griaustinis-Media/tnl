(ns {{ namespace }}
  (:require [gm.source.{{ source.type }} :as source]
            [gm.pipeline.core :as pipeline]
            [gm.sink.core :as sink]
            [gm.sink.{{ sink.type }} :as {{ sink.type }}]
            {% if watermark_enabled %}[gm.utils.watermark :as watermark]{% endif %}
            [clojure.tools.logging :as log])
  (:gen-class))

;; Configuration
(def config
  {:source (merge {:type :{{ source.type }}}
                  {% if source.type == "csv" %}{:file-path (or (System/getenv "CSV_FILE") "{{ source.default_host }}/{{ source.table }}.csv")
                   :delimiter ","}
                  {% else %}{:contact-points [(or (System/getenv "{{ source.type | upcase }}_HOST") "{{ source.default_host }}")]
                   :port {{ source.default_port }}
                   :username (System/getenv "{{ source.type | upcase }}_USER")
                   :password (System/getenv "{{ source.type | upcase }}_PASSWORD")
                   {% if source.schema %}:keyspace "{{ source.schema }}"{% endif %}}
                  {% endif %})

   :sink (merge {:type :{{ sink.type }}}
                {{ sink.config_template }})

   :pipeline {:batch-size {{ batch_size }}
              :source-table "{{ source.table }}"
              :source-type "{{ source.type }}"
              :dest-table "{{ sink.table }}"
              :timestamp-column :{{ timestamp_column }}
              :id-column :{{ id_column | default: "id" }}
              {% if watermark_enabled %}:watermark-file ".pipeline-watermark.edn"{% endif %}}})

(def transform-record (pipeline/make-transform-record config))

{% if watermark_enabled %}
;; Incremental pipeline execution
(defn run-incremental-pipeline []
  (log/info "Starting incremental {{ source.type }} -> {{ sink.type }} pipeline")
  (let [start-time (System/currentTimeMillis)
        watermark-file (:watermark-file (:pipeline config))
        wm (watermark/load-watermark watermark-file)
        {% if source.type == "csv" %}
        last-row (if wm (:last-row-number wm) 0)
        {% else %}
        timestamp-col (:timestamp-column (:pipeline config))
        id-col (:id-column (:pipeline config))
        {% endif %}]

    (log/info "Watermark stats:" (watermark/watermark-stats wm))
    {% if source.type == "csv" %}
    (log/info "Starting from row:" last-row)
    {% endif %}

    (let [source-conn (-> (source/create-adapter)
                          (source/connect (:source config)))
          sink-conn (-> ({{ sink.type }}/create-adapter (:sink config))
                       (sink/connect (:sink config)))]

      (try
        (let [base-query (-> (source/query-spec (:source-table (:pipeline config)))
                             (source/select-columns [{% for col in columns %}:{{ col }}{% unless forloop.last %} {% endunless %}{% endfor %}]))
              
              {% if source.type == "csv" %}
              ;; CSV: Apply offset based on watermark
              query (if wm
                     (do
                       (log/info "Fetching records after row" last-row)
                       (source/offset base-query (inc last-row)))
                     (do
                       (log/info "No watermark found, fetching all records")
                       base-query))
              
              source-data (source/fetch source-conn query)
              filtered-data source-data
              {% else %}
              ;; Database: Build composite incremental condition
              incremental-condition (watermark/build-incremental-condition wm timestamp-col id-col)
              
              query (if incremental-condition
                      (do
                        (log/info "Fetching records with composite condition")
                        (-> base-query
                            (source/where incremental-condition)
                            (source/allow-filtering)))
                      (do
                        (log/info "No watermark found, fetching all records")
                        base-query))
              
              source-data (source/fetch source-conn query)
              filtered-data (watermark/filter-already-processed source-data wm timestamp-col id-col)
              {% endif %}
              
              record-count (count filtered-data)]

          (log/info "Fetched" record-count "records")

          (if (zero? record-count)
            {:success true :records-processed 0 :message "No new data"}

            (let [transformed-data (map transform-record filtered-data)
                  {% if source.type == "csv" %}
                  max-watermark (watermark/find-max-row-number filtered-data)
                  {% else %}
                  [max-timestamp ids-at-max] (watermark/find-max-timestamp filtered-data timestamp-col id-col)
                  max-watermark max-timestamp
                  {% endif %}]

              (log/info "Max watermark:" max-watermark {% if source.type != "csv" %}"with" (count ids-at-max) "records"{% endif %})

              (let [result (if (> record-count (:batch-size (:pipeline config)))
                             (sink/batch-insert sink-conn
                                               (:dest-table (:pipeline config))
                                               transformed-data
                                               (:batch-size (:pipeline config)))
                             (sink/insert sink-conn
                                         (:dest-table (:pipeline config))
                                         transformed-data))]

                {% if source.type == "csv" %}
                (watermark/save-watermark watermark-file max-watermark
                                        {:records-processed record-count})
                {% else %}
                (watermark/save-watermark watermark-file max-watermark ids-at-max
                                        {:records-processed record-count})
                {% endif %}

                {:success true
                 :records-processed record-count
                 :elapsed-ms (- (System/currentTimeMillis) start-time)
                 {% if source.type == "csv" %}
                 :previous-row last-row
                 :new-row max-watermark
                 {% else %}
                 :previous-watermark (:last-timestamp wm)
                 :new-watermark max-watermark
                 :processed-ids (count ids-at-max)
                 {% endif %}}))))

        (finally
          (source/disconnect source-conn)
          (sink/disconnect sink-conn))))))

;; Full reload
(defn run-full-reload []
  (log/info "Starting FULL RELOAD")
  (watermark/delete-watermark (:watermark-file (:pipeline config)))
  (run-incremental-pipeline))
{% endif %}

;; Regular pipeline
(defn run-pipeline []
  (log/info "Starting {{ source.type }} -> {{ sink.type }} pipeline")
    (let [start-time (System/currentTimeMillis)
          source-conn (-> (source/create-adapter)
                          (source/connect (:source config)))
          sink-conn (-> ({{ sink.type }}/create-adapter (:sink config))
                       (sink/connect (:sink config)))]
    (try
      (let [base-query (-> (source/query-spec (:source-table (:pipeline config)))
                          (source/select-columns [{% for col in columns %}:{{ col }}{% unless forloop.last %} {% endunless %}{% endfor %}]))

            ;; Apply static WHERE conditions if any
            {% if conditions.size > 0 %}
            where-conditions (pipeline/build-where-clause [
              {% for cond in conditions %}
              {:type :{{ cond.type }}
               :column :{{ cond.column }}
               {% if cond.type == "in_expression" %}
               :values [{{ cond.values_formatted }}]
               :negated {{ cond.negated }}
               {% else %}
               :operator "{{ cond.operator }}"
               :value {{ cond.value }}
               {% endif %}}{% unless forloop.last %},{% endunless %}
              {% endfor %}])
            
            query (source/where base-query where-conditions)
            {% else %}
            query base-query
            {% endif %}

            
            source-data (source/fetch source-conn query)
            record-count (count source-data)]

        (log/info "Fetched" record-count "records")

        (let [transformed-data (map transform-record source-data)
              result (sink/insert sink-conn
                                 (:dest-table (:pipeline config))
                                 transformed-data)]

          {:success true
           :records-processed record-count
           :elapsed-ms (- (System/currentTimeMillis) start-time)}))

      (finally
        (source/disconnect source-conn)
        (sink/disconnect sink-conn)))))

;; Main entry point
(defn -main [& args]
  (let [mode (first args)]
    (case mode
      {% if watermark_enabled %}"incremental" (run-incremental-pipeline)
      "full-reload" (run-full-reload)
      {% endif %}(run-pipeline))))
